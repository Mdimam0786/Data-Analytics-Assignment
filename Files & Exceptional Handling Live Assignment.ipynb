{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4ec714-55bf-417a-b8a5-0f94c5acacb8",
   "metadata": {},
   "source": [
    "Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where \n",
    "multiprocessing is a better choice.\n",
    "\n",
    "Ans:- \n",
    "\n",
    "Scenarios Where Multithreading is Preferable to Multiprocessing:\n",
    "\n",
    "\n",
    "1. I/O-bound Tasks:\n",
    "\n",
    "   Multithreading is ideal for tasks that spend much time waiting for input/output operations, such as reading      from a file, making network requests, or waiting for user input. Since threads can run concurrently within      the same process, they can handle multiple I/O operations efficiently while allowing the CPU to switch          between tasks during idle periods.\n",
    "\n",
    "   Example: A web server handling multiple client requests (most of the time spent waiting for responses).  \n",
    "   \n",
    "   \n",
    "2. Lightweight Operations:\n",
    "\n",
    "   Threads are lightweight compared to processes. If our task involves simple, short-lived operations where the    overhead of creating separate processes is unnecessary, multithreading is more efficient.\n",
    "\n",
    "   Example: Real-time data fetching and displaying, like updating UI elements based on incoming data.\n",
    "   \n",
    "   \n",
    "3. Shared Memory Usage:\n",
    "\n",
    "   Since threads run within the same memory space, they can easily share data without the need for complex          inter-process communication (IPC). This makes multithreading better when tasks need to share resources or        modify shared variables quickly.\n",
    "\n",
    "   Example: In-memory caching or tasks that update a shared dataset.\n",
    "    \n",
    "    \n",
    "4. Low CPU Overhead:\n",
    "\n",
    "   The overhead associated with thread creation and context switching is lower than that of processes. For          tasks where performance is crucial, and context switching needs to be minimized, multithreading is a better      choice.\n",
    "     \n",
    "   Example: A program that monitors a large number of file changes without heavy computation.\n",
    "      \n",
    "      \n",
    "      \n",
    "Scenarios Where Multiprocessing is Preferable to Multithreading:\n",
    "\n",
    "\n",
    "1. CPU-bound Tasks:\n",
    "\n",
    "   For tasks that are heavily dependent on CPU resources, like mathematical computations or image processing,       multiprocessing is preferable. This is because each process runs in its own memory space, allowing the full     use of multiple CPU cores. Threads in Python are limited by the Global Interpreter Lock (GIL), which can         restrict performance for CPU-bound tasks.\n",
    "\n",
    "\n",
    "    Example: Image rendering, scientific simulations, or machine learning model training.\n",
    "    \n",
    "2. Task Isolation:\n",
    "\n",
    "   Multiprocessing is better when you want strong isolation between tasks. Since each process has its own memory    space, bugs or crashes in one process wonâ€™t affect others, providing better fault tolerance.\n",
    "\n",
    "   Example: Running independent parallel tasks in a distributed system, where each task must be fully isolated      for security or stability reasons.\n",
    "   \n",
    "3. Avoiding GIL Restrictions (Python-specific):\n",
    "\n",
    "   In languages like Python, the GIL prevents multiple threads from executing Python bytecode simultaneously in    a single process. If you are dealing with Python code that is CPU-bound and you need to bypass the GIL,          multiprocessing is the better choice.\n",
    "\n",
    "   Example: Heavy numerical computations or tasks requiring parallel processing in Python.\n",
    "   \n",
    "4. High Resource Demands:\n",
    "\n",
    "   If the task requires significant memory or CPU resources, running it in a separate process is better, as        processes are independent and can utilize the available hardware better.\n",
    "\n",
    "   Example: Data analysis on very large datasets that need parallel processing to handle memory efficiently.\n",
    "   \n",
    "\n",
    "Conclusion:\n",
    "\n",
    "=> Multithreading is generally better suited for I/O-bound tasks, lightweight operations, or scenarios where        threads need to share memory easily.\n",
    "\n",
    "\n",
    "=> Multiprocessing is preferable for CPU-bound tasks, or when tasks need to be isolated from each other and the    GIL in Python needs to be bypassed for performance reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b833394-8f31-4456-ae56-9a644e61dffd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7c274c7-322e-4df1-af15-130e7be117e8",
   "metadata": {},
   "source": [
    "Q2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
    "\n",
    "Ans:-\n",
    "\n",
    "A process pool is a mechanism in multiprocessing that allows for the efficient management of multiple processes by preallocating a fixed number of worker processes and reusing them to execute tasks. Rather than creating and destroying a new process for every task, which can be costly in terms of time and system resources, a pool of worker processes is created at the start and reused throughout the program's execution.\n",
    "\n",
    "\n",
    "Key Features of a Process Pool:\n",
    "\n",
    "\n",
    "1. Predefined Number of Processes:\n",
    "\n",
    "    The pool is initialized with a fixed number of worker processes. These processes are typically fewer than       the number of tasks, and the tasks are distributed to the workers as they become available.\n",
    "    \n",
    "2. Efficient Task Distribution:\n",
    "\n",
    "   The process pool automatically manages the task distribution. It assigns new tasks to worker processes that      are idle, reducing the overhead of process creation and destruction.\n",
    "   \n",
    "   \n",
    "3. Task Queueing:\n",
    "\n",
    "   Tasks that are submitted to the pool are placed in a queue, and as soon as a worker process becomes free, it    picks up the next task from the queue.\n",
    "   \n",
    "   \n",
    "4. Parallel Execution:\n",
    "\n",
    "   Since each process in the pool runs independently, the tasks are executed in parallel, making full use of the    available CPU cores.\n",
    "   \n",
    "   \n",
    "5. Resource Management:\n",
    "\n",
    "   By limiting the number of processes, a process pool ensures that system resources (like memory and CPU) are      used efficiently. Without a pool, spawning too many processes can overwhelm the system.\n",
    "   \n",
    "   \n",
    "How It Helps in Managing Multiple Processes Efficiently:\n",
    "\n",
    "\n",
    "1. Reduces Overhead:\n",
    "\n",
    "   The overhead associated with creating and destroying processes is significantly reduced. Instead of creating    a new process for each task, a fixed number of processes are created once and reused, which saves time and      resources.\n",
    "   \n",
    "   \n",
    "2. Efficient Use of CPU Cores:\n",
    "\n",
    "   By reusing the worker processes, the pool ensures that the system's CPU cores are utilized efficiently          without overloading them. The tasks are executed in parallel, allowing the system to perform more work in        less time.\n",
    "   \n",
    "   \n",
    "3. Simplifies Code:\n",
    "\n",
    "   The process pool abstracts the complexity of managing individual processes. Developers do not need to            manually create and manage processes; they can simply submit tasks to the pool and let it handle the rest.\n",
    "   \n",
    "   \n",
    "4. Balanced Workload:\n",
    "\n",
    "   The pool automatically balances the workload across the available worker processes, ensuring that no single      process is overloaded while others remain idle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607491e4-8f63-42fe-acf8-e09fc3c6ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 is being processed by process 1235Task 1 is being processed by process 1234Task 3 is being processed by process 1236Task 4 is being processed by process 1237\n",
      "\n",
      "\n",
      "\n",
      "Task 5 is being processed by process 1235Task 7 is being processed by process 1234Task 8 is being processed by process 1237Task 6 is being processed by process 1236\n",
      "\n",
      "\n",
      "\n",
      "Results: [2, 4, 6, 8, 10, 12, 14, 16]\n"
     ]
    }
   ],
   "source": [
    "# Example in Python using multiprocessing.Pool:\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "def worker_function(task):\n",
    "    print(f\"Task {task} is being processed by process {os.getpid()}\")\n",
    "    return task * 2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a process pool with 4 workers\n",
    "    with Pool(4) as pool:\n",
    "        tasks = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        \n",
    "        # Map the tasks to the pool and get results\n",
    "        results = pool.map(worker_function, tasks)\n",
    "        \n",
    "        print(\"Results:\", results)\n",
    "        \n",
    "\n",
    "# 1.Imports: Ensure that you have imported Pool from the multiprocessing module and os to access the process ID.\n",
    "\n",
    "# 2. Worker Function: The worker_function processes each task and prints which process is handling it using os.getpid().\n",
    "\n",
    "# 3. Process Pool: The with Pool(4) as pool: creates a pool of 4 worker processes.\n",
    "\n",
    "# 4. Mapping Tasks: pool.map(worker_function, tasks) distributes the tasks list across the worker processes.\n",
    "\n",
    "# 5. Printing Results: After processing, it prints the results.   \n",
    "\n",
    "\n",
    "# A process pool is an efficient way to handle multiple tasks in parallel without the overhead of managing individual processes. \n",
    "# It reduces the complexity of parallel programming and optimizes the use of system resources, \n",
    "# making it a crucial tool for parallel processing in many real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a38ceb-1f30-450c-92f1-a1eef78df990",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c2a68a1-77de-4f16-95dc-1c551361b9d7",
   "metadata": {},
   "source": [
    "Q3.Explain what multiprocessing is and why it is used in Python programs.\n",
    "\n",
    "Ans:- \n",
    "\n",
    "What is Multiprocessing?\n",
    "\n",
    "\n",
    "Multiprocessing is a technique used in computing where multiple processes are run concurrently, allowing a program to make full use of the available CPU cores. Each process runs independently and has its own memory space, enabling parallel execution of tasks.\n",
    "\n",
    "\n",
    "In Python, multiprocessing refers to the ability to spawn separate processes to execute tasks in parallel, thus overcoming limitations like the Global Interpreter Lock (GIL). The GIL is a mechanism in Python that restricts the execution of multiple threads at once in a single process, which can limit performance for CPU-bound tasks.\n",
    "\n",
    "Why is Multiprocessing Used in Python Programs?\n",
    "\n",
    "\n",
    "1. Bypassing the Global Interpreter Lock (GIL):\n",
    "\n",
    "=>  The GIL allows only one thread to execute Python bytecode at a time, even on multi-core systems. This makes     threading less efficient for CPU-bound tasks. Multiprocessing, on the other hand, uses separate memory           spaces for each process, thus avoiding the GIL and allowing true parallelism on multi-core CPUs.\n",
    "\n",
    "=>  Use Case: For tasks that require heavy computation (e.g., mathematical calculations, data processing),           multiprocessing enables the program to leverage all CPU cores, significantly improving performance.\n",
    "\n",
    "\n",
    "2. Improved Performance for CPU-bound Tasks:\n",
    "\n",
    "\n",
    "=> For tasks that are computation-heavy (CPU-bound), multiprocessing can be more efficient because it allows        tasks to be divided across multiple cores, running in parallel.\n",
    "\n",
    "\n",
    "=> Use Case: Video rendering, image processing, machine learning model training.\n",
    "\n",
    "\n",
    "3. Independent Execution of Tasks:\n",
    "\n",
    "=> Each process in multiprocessing runs independently of others and has its own memory space. This isolation        ensures that one process's failure doesnâ€™t affect others, providing better fault tolerance.\n",
    "\n",
    "\n",
    "=> Use Case: Running multiple independent operations such as batch processing jobs in parallel.\n",
    "\n",
    "\n",
    "4. Better Utilization of System Resources:\n",
    "\n",
    "=> Modern systems come with multi-core processors, and multiprocessing allows a Python program to use multiple      CPU cores effectively, maximizing computational resources.\n",
    "\n",
    "=> Use Case: Data analysis tasks where large datasets can be divided and processed in parallel.\n",
    "\n",
    "\n",
    "5. Parallel Processing:\n",
    "\n",
    "=> Multiprocessing enables tasks to run simultaneously on different cores, leading to faster execution times in    certain scenarios. This is particularly useful when tasks can be broken down into independent subtasks.\n",
    "\n",
    "\n",
    "=> Use Case: Simulating a large number of independent calculations, scientific simulations, or parallel            processing of multiple files.\n",
    "\n",
    "\n",
    "6. Efficient for Long-running Tasks:\n",
    "\n",
    "=> Multiprocessing is efficient for tasks that take a long time to complete, as it allows different processes to    execute simultaneously, reducing the overall execution time.\n",
    "\n",
    "\n",
    "=> Use Case: Web scraping tasks, where multiple web pages are fetched and processed concurrently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3c4624-c9be-4f6f-83c8-245cb4c3ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0 is starting.\n",
      "Task 1 is starting.\n",
      "Task 2 is starting.\n",
      "Task 3 is starting.\n",
      "Task 4 is starting.\n",
      "Task 0 is finished.\n",
      "Task 1 is finished.\n",
      "Task 2 is finished.\n",
      "Task 3 is finished.\n",
      "Task 4 is finished.\n",
      "All tasks are complete.\n"
     ]
    }
   ],
   "source": [
    "# Example in Python using the multiprocessing module:\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def worker_function(task_number):\n",
    "    print(f\"Task {task_number} is starting.\")\n",
    "    time.sleep(2)\n",
    "    print(f\"Task {task_number} is finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create multiple processes\n",
    "    processes = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=worker_function, args=(i,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    # Wait for all processes to complete\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(\"All tasks are complete.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# => Multiple Processes: The program creates 5 separate processes, each running worker_function().\n",
    "\n",
    "\n",
    "# => Parallel Execution: The tasks run in parallel, \n",
    "# and the program waits for all processes to complete using p.join().\n",
    "\n",
    "\n",
    "# When Should You Use Multiprocessing?\n",
    "\n",
    "\n",
    "# => CPU-bound tasks: Tasks that require heavy computations and need to fully utilize multiple CPU cores.\n",
    "\n",
    "\n",
    "# => Parallelism: When true parallelism is required (e.g., independent and long-running tasks).\n",
    "\n",
    "\n",
    "# => Avoiding GIL: When the Python GIL becomes a performance bottleneck for CPU-intensive operations.\n",
    "\n",
    "\n",
    "\n",
    "# Multiprocessing is an essential tool in Python for achieving parallel execution and improving performance in CPU-bound tasks.\n",
    "# By leveraging multiple processes, Python programs can fully utilize modern multi-core processors, making them more efficient, faster,\n",
    "# and better suited to handle resource-intensive operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f3639-b3d5-4bc7-9f72-c741c6dbf49a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16c9b122-9832-4d9d-95fb-d448bb8a7c8d",
   "metadata": {},
   "source": [
    "Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another \n",
    "thread removes numbers from the list. Implement a mechanism to avoid race conditions using \n",
    "threading.Lock.\n",
    "\n",
    "Ans:-\n",
    "\n",
    "To avoid race conditions when multiple threads modify shared data (such as adding and removing numbers from a list), we can use a threading.Lock. A race condition occurs when two or more threads try to access or modify shared data at the same time, which can lead to inconsistent or incorrect results. The Lock ensures that only one thread can modify the shared resource (in this case, the list) at any given time.\n",
    "\n",
    "Hereâ€™s a Python program that demonstrates how to implement this using threading.Lock:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455013c0-c076-4750-959a-8670471ecec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 to the list. Current list: [1]\n",
      "Added 2 to the list. Current list: [1, 2]\n",
      "Removed 1 from the list. Current list: [2]\n",
      "Added 3 to the list. Current list: [2, 3]\n",
      "Added 4 to the list. Current list: [2, 3, 4]\n",
      "Removed 2 from the list. Current list: [3, 4]\n",
      "Added 5 to the list. Current list: [3, 4, 5]\n",
      "Removed 3 from the list. Current list: [4, 5]\n",
      "Removed 4 from the list. Current list: [5]\n",
      "Removed 5 from the list. Current list: []\n",
      "Final list: []\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared list\n",
    "shared_list = []\n",
    "\n",
    "# Create a lock object\n",
    "list_lock = threading.Lock()\n",
    "\n",
    "# Function for adding numbers to the list\n",
    "def add_to_list():\n",
    "    for i in range(1, 6):\n",
    "        with list_lock:  # Acquire the lock before modifying the list\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i} to the list. Current list: {shared_list}\")\n",
    "        time.sleep(1)  # Simulate time taken for adding\n",
    "\n",
    "# Function for removing numbers from the list\n",
    "def remove_from_list():\n",
    "    for i in range(1, 6):\n",
    "        time.sleep(1.5)  # Delay to let the add thread add some numbers\n",
    "        with list_lock:  # Acquire the lock before modifying the list\n",
    "            if shared_list:\n",
    "                removed = shared_list.pop(0)\n",
    "                print(f\"Removed {removed} from the list. Current list: {shared_list}\")\n",
    "\n",
    "# Create threads for adding and removing numbers\n",
    "add_thread = threading.Thread(target=add_to_list)\n",
    "remove_thread = threading.Thread(target=remove_from_list)\n",
    "\n",
    "# Start the threads\n",
    "add_thread.start()\n",
    "remove_thread.start()\n",
    "\n",
    "# Wait for both threads to finish\n",
    "add_thread.join()\n",
    "remove_thread.join()\n",
    "\n",
    "print(\"Final list:\", shared_list)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Shared List: shared_list is the resource that both threads will modify.\n",
    "\n",
    "\n",
    "# 2. Lock Object: list_lock is a Lock object used to synchronize access to the list.\n",
    "\n",
    "\n",
    "# 3. Thread Functions:\n",
    "\n",
    "# => add_to_list(): This thread adds numbers (1 to 5) to the list. It acquires the lock using with list_lock to ensure safe access to the list.\n",
    "\n",
    "# => remove_from_list(): This thread removes numbers from the list, also using the lock to avoid race conditions.\n",
    "\n",
    "\n",
    "# 4. Thread Execution:\n",
    "\n",
    "# => The add_thread starts first, adding numbers to the list.\n",
    "\n",
    "# => The remove_thread starts shortly after, removing numbers from the list.\n",
    "\n",
    "# 5. Race Condition Avoidance: The with list_lock block ensures that only one thread can access the list at any given time, \n",
    "# preventing race conditions.\n",
    "\n",
    "\n",
    "# 6. Sleep Delays: These are added to simulate time taken by each operation and to demonstrate how locking ensures thread-safe modifications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25202f-4980-48c7-9b21-dc575ab240a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5963d021-6c96-4ca7-b23e-af372dd425e8",
   "metadata": {},
   "source": [
    "Q5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
    "\n",
    "\n",
    "Ans:-\n",
    "\n",
    "In Python, sharing data between threads and processes requires special tools and methods to avoid issues like race conditions (when two threads or processes access the same data at the same time). Below are the common methods and tools available for safely sharing data:\n",
    "\n",
    "For Threads:\n",
    "\n",
    "1. threading.Lock:\n",
    "\n",
    "=> A Lock is a synchronization primitive that prevents multiple threads from accessing a shared resource (e.g., a      list or a variable) at the same time.\n",
    "\n",
    "\n",
    "=> When one thread acquires the lock, other threads have to wait until the lock is released, ensuring that only one    thread can modify the shared data at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb21023c-5b85-4f5a-aae9-044a2fcdfd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "\n",
    "import threading\n",
    "lock = threading.Lock()\n",
    "\n",
    "def modify_data():\n",
    "    with lock:\n",
    "        # Critical section where data is modified\n",
    "        shared_data += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbfbc99-0a47-4d75-85b6-489ce163dd00",
   "metadata": {},
   "source": [
    "2. threading.RLock:\n",
    "\n",
    "=> An RLock (reentrant lock) is like a Lock, but it can be acquired multiple times by the same thread without          causing a deadlock.\n",
    "\n",
    "=> Useful when the same thread needs to acquire the lock more than once, especially in recursive functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d4e44-2768-47b4-b585-f45282e24b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "rlock = threading.RLock()\n",
    "with rlock:\n",
    "    # Thread-safe code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0960a03-726c-4a0f-a6d3-f9d4e8ab675d",
   "metadata": {},
   "source": [
    "3. threading.Event:\n",
    "\n",
    "=> An Event is used for communication between threads. One thread can signal an event, and other threads can wait      for that event to occur.\n",
    "\n",
    "=> It doesn't lock data but synchronizes threads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6ce8d-819e-4b4a-b904-63ac05feae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "event = threading.Event()\n",
    "event.set()  # Signals that an event has occurred\n",
    "event.wait()  # Waits for the event\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f3bdf-75c1-44a7-a120-50bdf5608a33",
   "metadata": {},
   "source": [
    "4. threading.Queue:\n",
    "\n",
    "=> A thread-safe data structure for sharing data between threads. It ensures safe access, as only one thread can      add or remove an item from the queue at a time.\n",
    "\n",
    "=> Queues are perfect for producer-consumer scenarios where one thread produces data, and another consumes it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9126d4-e0f1-4d4e-ac6f-b64fded5fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "from queue import Queue\n",
    "q = Queue()\n",
    "\n",
    "def producer():\n",
    "    q.put(item)\n",
    "\n",
    "def consumer():\n",
    "    item = q.get()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b6be9-2d2a-4c78-8d8c-cf3e1e39bcd5",
   "metadata": {},
   "source": [
    "For Processes:\n",
    "    \n",
    "\n",
    "1. multiprocessing.Queue:\n",
    "\n",
    "=> Similar to threading.Queue, but works for processes. It's a thread-safe, process-safe data structure for sharing    data between different processes.\n",
    "\n",
    "=> Processes can put items into the queue and retrieve them safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8c197-a807-414e-89a8-76724d5af161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue\n",
    "q = Queue()\n",
    "\n",
    "def producer():\n",
    "    q.put(data)\n",
    "\n",
    "def consumer():\n",
    "    data = q.get()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ce532-e71c-4e67-8987-0cc2db042b13",
   "metadata": {},
   "source": [
    "2. multiprocessing.Value and multiprocessing.Array:\n",
    "\n",
    "=> Value: Allows sharing a single value (like an integer or float) between processes.\n",
    "\n",
    "=> Array: Allows sharing an array of values between processes.\n",
    "\n",
    "=> Both ensure that updates to the data are thread-safe and protected by locks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3acd9f-1c8a-4f68-bb5d-24643a681c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "from multiprocessing import Value, Array\n",
    "num = Value('i', 0)  # Shared integer\n",
    "arr = Array('i', [0, 1, 2, 3])  # Shared array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb2a03-bf6a-43db-9bd8-210b0fc6e8e9",
   "metadata": {},
   "source": [
    "3. multiprocessing.Manager:\n",
    "\n",
    "=> A Manager provides a way to share complex data structures like dictionaries, lists, or other custom objects        between processes.\n",
    "\n",
    "=> It handles the synchronization behind the scenes, making it safe to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e36c7-cf82-4d7c-a03f-9737d57b5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "from multiprocessing import Manager\n",
    "manager = Manager()\n",
    "shared_dict = manager.dict()  # Shared dictionary between processes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad92f3-888a-4dc0-8e64-804c247894d9",
   "metadata": {},
   "source": [
    "4. multiprocessing.Lock:\n",
    "\n",
    "=> Similar to threading.Lock, but for processes. It ensures that only one process can access the shared resource at    a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea75b4-8d5e-41ba-b33d-583af086ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "from multiprocessing import Lock\n",
    "lock = Lock()\n",
    "\n",
    "def modify_data():\n",
    "    with lock:\n",
    "        # Safely modify shared data\n",
    "        shared_data += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2883d-2844-40cd-bdf9-4a746223da88",
   "metadata": {},
   "source": [
    "5. multiprocessing.Pipe:\n",
    "\n",
    "=> A Pipe allows two processes to communicate by sending and receiving data. It's a low-level way of inter-process    communication, but very efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3146ca9-313a-4fad-bdb2-7fca82c43a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "from multiprocessing import Pipe\n",
    "parent_conn, child_conn = Pipe()\n",
    "\n",
    "parent_conn.send(data)  # Send data\n",
    "received_data = child_conn.recv()  # Receive data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eea81e-04ff-4e95-add3-3cda9e6c3da5",
   "metadata": {},
   "source": [
    "\n",
    "=> For threads: Use Lock, RLock, Event, or Queue to safely share data between threads.\n",
    "\n",
    "=> For processes: Use multiprocessing.Queue, Value, Array, Manager, Lock, or Pipe for safe communication and data      sharing between processes.\n",
    "\n",
    "\n",
    "These tools ensure safe, efficient data sharing while preventing race conditions and other concurrency issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff76bc9-ae5b-47cb-8ae7-621ee66d444c",
   "metadata": {},
   "source": [
    "Q6. Discuss why itâ€™s crucial to handle exceptions in concurrent programs and the techniques available for doing.\n",
    "\n",
    "\n",
    "Ans:-\n",
    "\n",
    "Why Itâ€™s Crucial to Handle Exceptions in Concurrent Programs:\n",
    "\n",
    "\n",
    "In concurrent programs, multiple threads or processes run at the same time, making exception handling even more important than in sequential programs. Failure to handle exceptions can lead to:\n",
    "\n",
    "1. Unpredictable Program Behavior: When an exception occurs in one thread or process, it can cause unpredictable or    incorrect behavior across the entire program. For example, if one thread crashes while holding a lock, other        threads might never be able to acquire it, causing a deadlock.\n",
    "\n",
    "\n",
    "2. Resource Leaks: Exceptions can cause a thread or process to terminate prematurely, leaving open files, network      connections, or unfreed memory, which can lead to resource exhaustion.\n",
    "\n",
    "\n",
    "3. Data Corruption: Concurrent programs often involve shared data. If an exception occurs while data is being          updated, it may leave the data in an inconsistent or corrupted state.\n",
    "\n",
    "\n",
    "4. Difficult Debugging: Concurrent programs are harder to debug because of the non-deterministic behavior of          threads and processes. Unhandled exceptions can lead to more complex bugs that are harder to trace.\n",
    "\n",
    "\n",
    "  Techniques for Handling Exceptions in Concurrent Programs:\n",
    "  \n",
    "  \n",
    "1. try-except Blocks in Threads/Processes:\n",
    "\n",
    "=> A simple and effective way to handle exceptions is by using try-except blocks inside each thread or process.        This ensures that individual threads or processes can catch and handle their own exceptions without affecting      others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55983b5-3bf6-417c-a84f-046665653810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "import threading\n",
    "\n",
    "def thread_function():\n",
    "    try:\n",
    "        # Code that might raise an exception\n",
    "        risky_operation()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred in thread: {e}\")\n",
    "\n",
    "thread = threading.Thread(target=thread_function)\n",
    "thread.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac348f29-1337-4cb1-bba8-3addd2e884c2",
   "metadata": {},
   "source": [
    "2. Handling Exceptions in the Main Thread:\n",
    "\n",
    "\n",
    "=> Sometimes, you want the main thread or process to be aware of any exceptions raised in worker threads or            processes. For this, you can catch exceptions in each worker and propagate them back to the main thread using      mechanisms like Queue or shared objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a13b94-fd53-4abd-9ca4-2e837511586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using Queueto pass exceptions:\n",
    "\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "def thread_function(queue):\n",
    "    try:\n",
    "        risky_operation()\n",
    "    except Exception as e:\n",
    "        queue.put(e)  # Pass the exception to the main thread\n",
    "\n",
    "q = Queue()\n",
    "thread = threading.Thread(target=thread_function, args=(q,))\n",
    "thread.start()\n",
    "\n",
    "# In the main thread\n",
    "try:\n",
    "    exc = q.get(block=False)  # Get the exception from the queue\n",
    "    raise exc\n",
    "except Queue.Empty:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937594c-f04c-4d1c-90f7-1c0923de4388",
   "metadata": {},
   "source": [
    "3. Using concurrent.futures:\n",
    "\n",
    "=> The concurrent.futures module provides a higher-level interface for managing threads and processes. It includes    a mechanism to handle exceptions in worker threads or processes. If an exception is raised in a worker, the        Future object captures the exception, which can then be re-raised in the main thread.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972bb65-7e98-4e4f-a756-2e1c43c217dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def risky_operation():\n",
    "    raise ValueError(\"An error occurred\")\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(risky_operation)\n",
    "    try:\n",
    "        future.result()  # This will re-raise any exception in the main thread\n",
    "    except Exception as e:\n",
    "        print(f\"Exception caught: {e}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760c7cb-0b0e-47b7-b286-0a89724fe79c",
   "metadata": {},
   "source": [
    "4. Graceful Termination with finally:\n",
    "\n",
    "=> Always use finally blocks to ensure that resources are properly cleaned up even if an exception occurs. This is    important for avoiding resource leaks, such as closing files, releasing locks, or terminating threads/processes    cleanly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c35d2-2e99-4f75-8c1a-321e6e048e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:-\n",
    "\n",
    "import threading\n",
    "\n",
    "def thread_function():\n",
    "    lock = threading.Lock()\n",
    "    try:\n",
    "        lock.acquire()\n",
    "        # Code that might raise an exception\n",
    "        risky_operation()\n",
    "    finally:\n",
    "        lock.release()  # Ensure the lock is released no matter what\n",
    "        print(\"Thread finished execution.\")\n",
    "\n",
    "thread = threading.Thread(target=thread_function)\n",
    "thread.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838dd9a-99b4-4394-a84c-296f276008f3",
   "metadata": {},
   "source": [
    "5. Timeouts and Watchdogs:\n",
    "\n",
    "=> In some cases, a thread or process might get stuck in an infinite loop or hang indefinitely. Setting timeouts or    using watchdog mechanisms can help terminate or restart unresponsive threads or processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce2308-bd2c-42b7-8897-4fe67a8295c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with threading.Timer:\n",
    "\n",
    "import threading\n",
    "\n",
    "def timeout_function():\n",
    "    print(\"Thread took too long to finish, terminating.\")\n",
    "\n",
    "timer = threading.Timer(5, timeout_function)  # Set a 5-second timeout\n",
    "timer.start()\n",
    "\n",
    "# Thread code here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c1d7e-c342-4af2-bdd1-2a670025b736",
   "metadata": {},
   "source": [
    "6. multiprocessing Exception Handling:\n",
    "\n",
    "=> In the multiprocessing module, exceptions raised in worker processes are not propagated to the main process by      default. You can use the Pool or Queue to propagate exceptions back to the main process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ae9e9-a0f8-4f50-bd9f-4c7c2192e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using multiprocessing.Pool:\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def risky_operation():\n",
    "    raise ValueError(\"Error in process\")\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    with Pool() as pool:\n",
    "        result = pool.apply_async(risky_operation)\n",
    "        try:\n",
    "            result.get()  # Will raise the exception here\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process: {e}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "# Handling exceptions in concurrent programs is crucial for ensuring consistent program behavior, resource management, and data integrity.\n",
    "# Techniques like try-except blocks, using concurrent.futures, handling timeouts, and properly propagating exceptions help avoid issues \n",
    "# and make concurrent programs more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a520b-ef04-4ec6-9903-794e8ec0dacb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1c44d3-48eb-475a-8c62-690d17d46404",
   "metadata": {},
   "source": [
    "Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. \n",
    "Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "Ans:-\n",
    "\n",
    "Hereâ€™s a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d446efe9-6117-4a67-b4c0-eef9c98ad4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 1 is 1\n",
      "Factorial of 2 is 2\n",
      "Factorial of 3 is 6\n",
      "Factorial of 4 is 24\n",
      "Factorial of 5 is 120\n",
      "Factorial of 6 is 720\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "# Function to calculate factorial\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "# List of numbers from 1 to 10\n",
    "numbers = range(1, 11)\n",
    "\n",
    "# Use ThreadPoolExecutor to manage the threads\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit the tasks to the thread pool and get results\n",
    "    results = executor.map(factorial, numbers)\n",
    "\n",
    "# Print the results\n",
    "for number, result in zip(numbers, results):\n",
    "    print(f\"Factorial of {number} is {result}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# 1.Factorial Function: The factorial function takes a number n and calculates its factorial using math.factorial(n).\n",
    "\n",
    "# 2.Thread Pool Executor:\n",
    "\n",
    "# => We create a ThreadPoolExecutor to manage multiple threads. \n",
    "# It makes handling concurrency easier by managing a pool of worker threads.\n",
    "\n",
    "# => The executor.map(factorial, numbers) method runs the factorial function concurrently on each number in the numbers list.\n",
    "\n",
    "# 3.Result Collection: The executor.map() returns the results for each factorial calculation, which we print alongside the number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a726f8-7d99-4e27-94b1-a764ece021e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0377a1-fcb3-4bc4-a779-88eb806a7c05",
   "metadata": {},
   "source": [
    "Q8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in \n",
    "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 \n",
    "processes).\n",
    "\n",
    "Ans:-\n",
    "\n",
    "Hereâ€™s a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel, and measures the time taken with different pool sizes (e.g., 2, 4, 8 processes):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfaee84-9eef-43e1-95e7-5a45ec694a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with pool size 2: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken with pool size 2: 0.0260 seconds\n",
      "\n",
      "Results with pool size 4: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken with pool size 4: 0.0372 seconds\n",
      "\n",
      "Results with pool size 8: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken with pool size 8: 0.0618 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to compute the square of a number\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "# List of numbers from 1 to 10\n",
    "numbers = range(1, 11)\n",
    "\n",
    "# Function to measure the time taken for computation with a given pool size\n",
    "def compute_with_pool_size(pool_size):\n",
    "    start_time = time.time()  # Record start time\n",
    "    \n",
    "    # Create a pool with the given size\n",
    "    with multiprocessing.Pool(pool_size) as pool:\n",
    "        results = pool.map(square, numbers)  # Compute squares in parallel\n",
    "    \n",
    "    end_time = time.time()  # Record end time\n",
    "    \n",
    "    print(f\"Results with pool size {pool_size}: {results}\")\n",
    "    print(f\"Time taken with pool size {pool_size}: {end_time - start_time:.4f} seconds\\n\")\n",
    "\n",
    "# Measure time with different pool sizes\n",
    "for pool_size in [2, 4, 8]:\n",
    "    compute_with_pool_size(pool_size)\n",
    "    \n",
    "\n",
    "# 1.Square Function: The square function computes the square of a given number n.\n",
    "\n",
    "# 2.Multiprocessing Pool:\n",
    "\n",
    "# => We use multiprocessing.Pool() to create a pool of worker processes. \n",
    "# The pool.map() function distributes the work across the processes to compute the square of each number in the numbers list.\n",
    "\n",
    "# 3.Timing:\n",
    "The time.time() function measures the time taken for the computation with different pool sizes (2, 4, and 8 processes).\n",
    "Loop: The program runs the computation for pool sizes of 2, 4, and 8, printing the results and time taken for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dbb89a-7f70-47d3-80ac-459fe3702eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331a98d-1158-46b7-aa01-fa65f700e592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab8b4b-6582-4dd9-b8b4-79b684f0e2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2262e8-e2b5-4172-8080-5a41a0e2112e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24681e1-0d05-40a2-afc1-2d2c12ec7778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819cca0-fe13-495e-b4a7-5fd5043d90e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf1e88-875d-41b6-a061-4d8066c11cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd670e0-210c-4874-b076-8a65495ae212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d1940-2d1d-422c-9437-fcffa33f3fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dc8e0-ce13-4b21-92ee-4433f41ecfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e34ee-8651-412f-9b23-53c7c260a259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd00db-e4ab-4f00-a12b-af3e9c35d5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
